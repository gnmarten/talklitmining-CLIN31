{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "variable-cross",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "import pandas as pd\n",
    "import csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils import data\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import classification_report\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "available-wages",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN SAMPLES: 573\n",
      "TEST SAMPLES: 144\n"
     ]
    }
   ],
   "source": [
    "#Uncomment for Aspect Category Experiments\n",
    "train = 'data/aspect_final_train.csv'\n",
    "test = 'data/aspect_final_test.csv'\n",
    "\n",
    "#Uncomment for Polarity Experiment\n",
    "#train = 'data/polarity_final_train.csv'\n",
    "#test = 'data/aspect_final_test.csv'\n",
    "\n",
    "with open(train) as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    train_data = [row for row in reader]\n",
    "with open(test) as fp:\n",
    "    reader = csv.reader(fp, delimiter=\",\", quotechar='\"')\n",
    "    test_data = [row for row in reader]\n",
    "    \n",
    "print(\"TRAIN SAMPLES: {}\".format(len(train_data)))\n",
    "print(\"TEST SAMPLES: {}\".format(len(test_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "altered-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_aspect(index_string, full_text):\n",
    "    indices = index_string.replace('[','').replace(']','').split(',')\n",
    "    aspect = ''\n",
    "    for index in indices:\n",
    "        aspect+= full_text.split()[int(index)] + ' '\n",
    "    return aspect.strip()\n",
    "\n",
    "def get_pos(sent_list,aspect_list):\n",
    "    first_pos = sent_list.index(aspect_list[0])\n",
    "    final_pos = []\n",
    "    for i in range(0,len(aspect_list)):\n",
    "        final_pos.append(first_pos+i)\n",
    "    return final_pos    \n",
    "\n",
    "class TalkLitDataset(data.Dataset):\n",
    "    def __init__(self, tagged_sents):\n",
    "        sents, aspects, tags = [], [], [] # list of lists\n",
    "        for sent in tagged_sents:\n",
    "            sent_tokens = tokenizer.encode(sent[0])\n",
    "            try:\n",
    "                aspect_tokens = tokenizer.encode(get_aspect(sent[1],sent[0]))[1:-1]\n",
    "            except:\n",
    "                print(sent[1])\n",
    "                print(sent[0])\n",
    "                continue\n",
    "            pos_aspects = get_pos(sent_tokens, aspect_tokens)\n",
    "            tag = sent[2]\n",
    "            sents.append(sent_tokens)\n",
    "            aspects.append(pos_aspects)\n",
    "            tags.append(tag)\n",
    "            \n",
    "        self.sents, self.aspects, self.tags = sents, aspects, tags\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sents)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        words, aspects, tags = self.sents[idx], self.aspects[idx], tag2idx[self.tags[idx]] # words, tags: string list\n",
    "        return words, aspects, tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "municipal-delaware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'META': 0, 'JURY': 1, 'ALLO-REFERENCES': 2, 'CONTENDER': 3, 'READING': 4, 'None': 5, 'TEXT': 6, 'ONSITE-AUDIENCE': 7}\n"
     ]
    }
   ],
   "source": [
    "tags = []\n",
    "for dat in train_data:\n",
    "    tags.append(dat[2])\n",
    "    \n",
    "tags = list(set(tags))\n",
    "\",\".join(tags)\n",
    "tag2idx = {tag:idx for idx, tag in enumerate(tags)}\n",
    "idx2tag = {idx:tag for idx, tag in enumerate(tags)}\n",
    "print(tag2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "absolute-ceremony",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "renewable-valley",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-german-cased\")\n",
    "model = BertModel.from_pretrained(\"bert-base-german-cased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "comparable-knock",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, vocab_size=None):\n",
    "        super().__init__()\n",
    "        self.model = BertModel.from_pretrained(\"bert-base-german-cased\", output_hidden_states=True)\n",
    "        self.fc = nn.Linear(768, vocab_size)\n",
    "        self.device = device\n",
    "\n",
    "    def forward(self, sent, aspects, y):\n",
    "        sent = torch.LongTensor(sent).to(device)\n",
    "        y = torch.LongTensor(y).to(device)\n",
    "        input_ids = sent.unsqueeze(0)  # Batch size 1\n",
    "        with torch.no_grad():\n",
    "            outputs = self.model(input_ids)\n",
    "            last_hidden_states = outputs.last_hidden_state[0]  # The last hidden-state is the first element of the output tuple\n",
    "            start = 0\n",
    "            end = len(last_hidden_states)-1\n",
    "            context_window = 5\n",
    "            \n",
    "            if aspects[0]-context_window>0:\n",
    "                start = aspects[0]-context_window\n",
    "            if aspects[-1]+context_window<len(last_hidden_states)-1:\n",
    "                end = aspects[-1]+context_window\n",
    "                \n",
    "            all_aspects = []\n",
    "            for i in range(start,end):\n",
    "                all_aspects.append(i)\n",
    "            bert_embeds = torch.zeros(len(all_aspects),768)\n",
    "            for i, aspect in enumerate(all_aspects):\n",
    "                bert_embeds[i] = last_hidden_states[aspect]\n",
    "                \n",
    "            bert_embeds = torch.mean(bert_embeds, axis=0)\n",
    "        logits = self.fc(bert_embeds)\n",
    "        y_hat = logits.argmax(-1)\n",
    "        return logits, y, y_hat, bert_embeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cosmetic-french",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TalkLitDataset(train_data)\n",
    "train_iter = data.DataLoader(dataset=train_dataset,\n",
    "                             batch_size=1,\n",
    "                             shuffle=True,\n",
    "                             num_workers=0)\n",
    "\n",
    "test_dataset = TalkLitDataset(test_data)\n",
    "test_iter = data.DataLoader(dataset=test_dataset,\n",
    "                             batch_size=1,\n",
    "                             shuffle=True,\n",
    "                             num_workers=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "veterinary-saying",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "573it [01:12,  7.89it/s]\n",
      "144it [00:17,  8.14it/s]\n"
     ]
    }
   ],
   "source": [
    "model = Net(vocab_size=len(tag2idx))\n",
    "model.to(device)\n",
    "model = nn.DataParallel(model)\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for i, batch in tqdm.tqdm(enumerate(train_iter)):\n",
    "        words, aspects, y = batch\n",
    "        _y = y\n",
    "        logits, y, _, bert_embeds = model(words, aspects, y)\n",
    "        logits = logits.view(-1, logits.shape[-1])\n",
    "        y = y.view(-1)\n",
    "        bert_embeds = bert_embeds.cpu().numpy()\n",
    "        y = int(y.cpu().numpy()[0])\n",
    "        X_train.append(bert_embeds)\n",
    "        y_train.append(y)\n",
    "        \n",
    "for i, batch in tqdm.tqdm(enumerate(test_iter)):\n",
    "        words, aspects, y = batch\n",
    "        _y = y\n",
    "        logits, y, _, bert_embeds = model(words, aspects, y)\n",
    "        logits = logits.view(-1, logits.shape[-1])\n",
    "        y = y.view(-1)\n",
    "        bert_embeds = bert_embeds.cpu().numpy()\n",
    "        y = int(y.cpu().numpy()[0])\n",
    "        X_test.append(bert_embeds)\n",
    "        y_test.append(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "seven-change",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER: Nearest Neighbors\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.72      0.66        57\n",
      "           1       0.33      0.40      0.36         5\n",
      "           2       0.64      0.49      0.55        37\n",
      "           4       1.00      0.33      0.50         3\n",
      "           5       0.26      0.41      0.32        22\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.86      0.46      0.60        13\n",
      "\n",
      "    accuracy                           0.53       145\n",
      "   macro avg       0.53      0.40      0.43       145\n",
      "weighted avg       0.55      0.53      0.52       145\n",
      "\n",
      "CLASSIFIER: Linear SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.84      0.74        57\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.72      0.76      0.74        37\n",
      "           4       0.67      0.67      0.67         3\n",
      "           5       0.44      0.36      0.40        22\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.58      0.54      0.56        13\n",
      "\n",
      "    accuracy                           0.64       145\n",
      "   macro avg       0.44      0.45      0.44       145\n",
      "weighted avg       0.58      0.64      0.60       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER: RBF SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      1.00      0.58        57\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.00      0.00      0.00        37\n",
      "           4       1.00      0.33      0.50         3\n",
      "           5       1.00      0.14      0.24        22\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.42       145\n",
      "   macro avg       0.34      0.21      0.19       145\n",
      "weighted avg       0.33      0.42      0.28       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/gaussian_process/kernels.py:411: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__length_scale is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\"The optimal value found for \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER: Gaussian Process\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.86      0.74        57\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.72      0.70      0.71        37\n",
      "           4       0.67      0.67      0.67         3\n",
      "           5       0.50      0.41      0.45        22\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.67      0.62      0.64        13\n",
      "\n",
      "    accuracy                           0.65       145\n",
      "   macro avg       0.46      0.46      0.46       145\n",
      "weighted avg       0.59      0.65      0.61       145\n",
      "\n",
      "CLASSIFIER: Decision Tree\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.68      0.53        57\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.50      0.35      0.41        37\n",
      "           4       0.50      0.33      0.40         3\n",
      "           5       0.13      0.09      0.11        22\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.71      0.38      0.50        13\n",
      "\n",
      "    accuracy                           0.41       145\n",
      "   macro avg       0.33      0.26      0.28       145\n",
      "weighted avg       0.39      0.41      0.38       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER: Random Forest\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.93      0.59        57\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.50      0.22      0.30        37\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.00      0.00      0.00        22\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       1.00      0.31      0.47        13\n",
      "\n",
      "    accuracy                           0.45       145\n",
      "   macro avg       0.28      0.21      0.19       145\n",
      "weighted avg       0.39      0.45      0.35       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER: Neural Net\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.74      0.69        57\n",
      "           1       0.50      0.20      0.29         5\n",
      "           2       0.71      0.68      0.69        37\n",
      "           4       0.50      0.67      0.57         3\n",
      "           5       0.36      0.41      0.38        22\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.50      0.54      0.52        13\n",
      "\n",
      "    accuracy                           0.59       145\n",
      "   macro avg       0.46      0.46      0.45       145\n",
      "weighted avg       0.56      0.59      0.57       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLASSIFIER: AdaBoost\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.47      0.53        57\n",
      "           1       0.00      0.00      0.00         5\n",
      "           2       0.32      0.81      0.46        37\n",
      "           4       0.00      0.00      0.00         3\n",
      "           5       0.14      0.05      0.07        22\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.00      0.00      0.00        13\n",
      "\n",
      "    accuracy                           0.40       145\n",
      "   macro avg       0.15      0.19      0.15       145\n",
      "weighted avg       0.35      0.40      0.34       145\n",
      "\n",
      "CLASSIFIER: Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68        57\n",
      "           1       1.00      0.40      0.57         5\n",
      "           2       0.58      0.70      0.63        37\n",
      "           4       0.75      1.00      0.86         3\n",
      "           5       0.46      0.50      0.48        22\n",
      "           6       0.00      0.00      0.00         8\n",
      "           7       0.64      0.54      0.58        13\n",
      "\n",
      "    accuracy                           0.61       145\n",
      "   macro avg       0.59      0.55      0.54       145\n",
      "weighted avg       0.59      0.61      0.59       145\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "names = [\"Nearest Neighbors\", \"Linear SVM\", \"RBF SVM\", \"Gaussian Process\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(3),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    SVC(gamma=2, C=1),\n",
    "    GaussianProcessClassifier(1.0 * RBF(1.0)),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=10, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()]\n",
    "\n",
    "for name, clf in zip(names, classifiers):\n",
    "    clf.fit(X_train, y_train)\n",
    "    predicted = clf.predict(X_test)\n",
    "    print(\"CLASSIFIER: {}\".format(name))\n",
    "    print(classification_report(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lined-wiring",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
